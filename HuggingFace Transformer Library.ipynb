{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c964b04b-2996-4fe7-a186-04a544afd199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c068b291-3363-4b07-8fb7-9a38a0da244c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ImportError: Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U í•´ê²°\n",
    "#! pip install -U accelerate\n",
    "#! pip install -U transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf2d594-7184-449a-9beb-4ed1a8bd586e",
   "metadata": {},
   "source": [
    "#### í—ˆê¹…í˜ì´ìŠ¤ íŠ¸ëœìŠ¤í¬ë¨¸ í™œìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ì‚¬ìš© ì‹œ \n",
    "!pip install transformers==4.40.1 datasets==2.19.0 huggingface_hub==0.23.0 -qq\n",
    "\n",
    "- huggingface transformer ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©í•˜ë©´ í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ í—ˆë¸Œì˜ ëª¨ë¸ì„ ì‰½ê²Œ ë¶ˆëŸ¬ì™€ ì‚¬ìš©ê°€ëŠ¥\n",
    "- **ê¼­ ì•Œì•„ì•¼ í•˜ëŠ” ì‚¬ì‹¤ì€ huggingfaceëŠ” ëª¨ë¸ì„ bodyì™€ headë¡œ êµ¬ë¶„í•œë‹¤. ì´ìœ ëŠ” ê°™ì€ ë°”ë””ë¥¼ ì‚¬ìš©í•˜ë©´ì„œ ë‹¤ë¥¸ ì‘ì—…ì— ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë§Œë“¤ê¸° ìœ„í•´ì„œë‹¤**\n",
    "- ëª¨ë¸ì˜ ë°”ë””ë§Œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆê³ , í—¤ë“œì™€ í•¨ê»˜ ë¶ˆëŸ¬ì˜¬ ìˆ˜ë„ ìˆë‹¤.\n",
    "- í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ì„ ì €ì¥í•  ë•Œ config.json íŒŒì¼ì´ í•¨ê»˜ ì €ì¥ë˜ëŠ”ë°,í•´ë‹¹ ì„¤ì • íŒŒì¼ì—ëŠ” **ëª¨ë¸ì˜ ì¢…ë¥˜,ì„¤ì • íŒŒë¼ë¯¸í„°,ì–´íœ˜ ì‚¬ì „ í¬ê¸°,í† í¬ë‚˜ì´ì € í´ë˜ìŠ¤ ë“±**ì´ ì €ì¥ëœë‹¤. ì´ë¥¼ ì°¸ê³ í•´ì„œ AutoModel,AutoTokenizer ëŠ” ì ì ˆí•œ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¶ˆëŸ¬ì˜´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "927e38e3-dcc7-407c-9057-f59f81fdb615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "## ëª¨ë¸ ë°”ë”” ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "from transformers import AutoModel\n",
    "model_id = 'klue/roberta-base'\n",
    "model= AutoModel.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e082db-ae4d-4b80-9aef-5a32b9fd9da8",
   "metadata": {},
   "source": [
    "AutoModelForSequenceClassificationì€ í…ìŠ¤íŠ¸ ì‹œí€€ìŠ¤ ë¶„ë¥˜ë¥¼ ìœ„í•œ í—¤ë“œê°€ í¬í•¨ëœ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¬ ë•Œ ì‚¬ìš©í•˜ëŠ” í´ë˜ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07104f58-5dd5-4f51-99bf-1d8c8ef918e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## í…ìŠ¤íŠ¸ ë¶„ë¥˜ í—¤ë“œê°€ ë¶™ì€ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "model_id = 'SamLowe/roberta-base-go_emotions'\n",
    "classification_model = AutoModelForSequenceClassification.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9d33cd-de13-4932-8bd5-03955a18c733",
   "metadata": {},
   "source": [
    "### í—ˆê¹… í˜ì´ìŠ¤ë¡œ ë¶ˆëŸ¬ì˜¨ ëª¨ë¸ì˜ ì €ì¥ ê²½ë¡œ\n",
    "~/.cache/huggingface/transformers/\n",
    "\n",
    "- AutoConfig ë¥¼ í™œìš©í•˜ë©´ ëª¨ë¸ì˜ íŠ¹ì„±ì„ í™•ì¸ í•  ìˆ˜ ìˆìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a73dc0a-2acd-4de6-82d1-9f9369009797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaConfig {\n",
      "  \"_name_or_path\": \"klue/roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "config = AutoConfig.from_pretrained(\"klue/roberta-base\")\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9789e269-ed5a-4e71-8988-dda9ad1cb9bf",
   "metadata": {},
   "source": [
    "### í† í¬ë‚˜ì´ì € \n",
    "- í† í¬ë‚˜ì´ì €ëŠ” í…ìŠ¤íŠ¸ë¥¼ í† í° ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê³  ê° í† í°ì„ ëŒ€ì‘ í•˜ëŠ” í† í° ì•„ì´ë””ë¡œ ë³€í™˜í•˜ê±°ë‚˜ í•„ìš”ì˜ ê²½ìš° íŠ¹ìˆ˜ í† í°ì„ ì¶”ê°€í•˜ëŠ” ì—­í• ë„ í•œë‹¤.\n",
    "- AutoTokenizer í´ë˜ìŠ¤ë¥¼ ì´ìš©í•´ í† í¬ë‚˜ì´ì €ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "887cecc9-1c5d-42e7-bd1f-fed504ff5fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_id = 'klue/roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1c09651-fde1-461e-ba8a-7b9010c018cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [0, 9157, 7461, 2190, 2259, 8509, 2138, 1793, 2855, 5385, 2200, 4835, 2088, 1793, 2855, 15129, 2200, 15070, 2205, 9253, 5177, 1793, 2855, 4140, 4008, 2069, 3605, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "['[CLS]', 'í† í¬', '##ë‚˜ì´', '##ì €', '##ëŠ”', 'í…ìŠ¤íŠ¸', '##ë¥¼', 'í† ', '##í°', 'ë‹¨ìœ„', '##ë¡œ', 'ë‚˜ëˆ„', '##ê³ ', 'í† ', '##í°', 'ì•„ì´ë””', '##ë¡œ', 'ë³€í™˜', '##í•˜', '##ê±°ë‚˜', 'íŠ¹ìˆ˜', 'í† ', '##í°', 'ì¶”ê°€', 'ì—­í• ', '##ì„', 'í•œë‹¤', '[SEP]']\n",
      "[CLS] í† í¬ë‚˜ì´ì €ëŠ” í…ìŠ¤íŠ¸ë¥¼ í† í° ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê³  í† í° ì•„ì´ë””ë¡œ ë³€í™˜í•˜ê±°ë‚˜ íŠ¹ìˆ˜ í† í° ì¶”ê°€ ì—­í• ì„ í•œë‹¤ [SEP]\n",
      "í† í¬ë‚˜ì´ì €ëŠ” í…ìŠ¤íŠ¸ë¥¼ í† í° ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê³  í† í° ì•„ì´ë””ë¡œ ë³€í™˜í•˜ê±°ë‚˜ íŠ¹ìˆ˜ í† í° ì¶”ê°€ ì—­í• ì„ í•œë‹¤\n"
     ]
    }
   ],
   "source": [
    "#í† í¬ë‚˜ì´ì € ì‚¬ìš©í•´ë³´ê¸°\n",
    "tokenized = tokenizer('í† í¬ë‚˜ì´ì €ëŠ” í…ìŠ¤íŠ¸ë¥¼ í† í° ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê³  í† í° ì•„ì´ë””ë¡œ ë³€í™˜í•˜ê±°ë‚˜ íŠ¹ìˆ˜ í† í° ì¶”ê°€ ì—­í• ì„ í•œë‹¤')\n",
    "print(tokenized)\n",
    "\n",
    "print(tokenizer.convert_ids_to_tokens(tokenized['input_ids']))\n",
    "\n",
    "print(tokenizer.decode(tokenized['input_ids']))\n",
    "\n",
    "print(tokenizer.decode(tokenized['input_ids'],skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cdc649-77c4-4d3b-af63-69950c472db3",
   "metadata": {},
   "source": [
    "- input_idsëŠ” í† í°í™” í–ˆì„ ë•Œ ê° í† í°ì´ í† í¬ë‚˜ì´ì € ì‚¬ì „ì˜ ëª‡ë²ˆì§¸ í•­ëª©ì¸ì§€ ë‚˜íƒ€ë‚¸ë‹¤.\n",
    "- ì²«ë²ˆì§¸ í•­ëª©ì€ 0 ì¸ë° ì´ëŠ” [CLS] í† í°ìœ¼ë¡œ ëŒ€ì‘ëœë‹¤.\n",
    "- attention_maskê°€ 1ì´ë©´ padding tokenì´ ì•„ë‹Œ ì‹¤ì œ í† í°ì„ ì˜ë¯¸í•¨.\n",
    "- token_type_idsê°€ 0 ì´ë©´ ì¼ë°˜ì ìœ¼ë¡œ ì²«ë²ˆì§¸ ë¬¸ì¥ì„ ì˜ë¯¸í•œë‹¤.\n",
    "- í† í° ì•„ì´ë””ë¥¼ ë‹¤ì‹œ í…ìŠ¤íŠ¸ë¡œ ëŒë¦¬ê³  ì‹¶ë‹¤ë©´ í† í¬ë‚˜ì´ì €ì˜ decode ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ê³ , ë§Œì•½ [CLS] ë‚˜ [SEP] ê³¼ ê°™ì€ íŠ¹ìˆ˜ í† í°ì„ ì œì™¸í•˜ê³ ì‹¶ìœ¼ë©´ skip_special_tokens ì¸ìë¥¼ Trueë¡œ ì„¤ì •í•˜ë©´ ëœë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a0cac48-2f32-4968-ae03-effca85399dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[0, 1656, 2517, 3135, 6265, 2], [0, 864, 2517, 3135, 6265, 2]], 'token_type_ids': [[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]}\n",
      "{'input_ids': [[0, 1656, 2517, 3135, 6265, 2, 864, 2517, 3135, 6265, 2]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "# ì—¬ëŸ¬ê°œ ë¬¸ì¥ ì²˜ë¦¬í•˜ê¸°\n",
    "print(tokenizer(['ì²«ë²ˆì§¸ ë¬¸ì¥','ë‘ë²ˆì§¸ ë¬¸ì¥']))\n",
    "# 2ê°œì˜ ë¬¸ì¥ì´ í•œë²ˆì— ëª¨ë¸ì— ì…ë ¥ë˜ê¸¸ ì›í•˜ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë¬¶ì–´ì•¼\n",
    "print(tokenizer([['ì²«ë²ˆì§¸ ë¬¸ì¥','ë‘ë²ˆì§¸ ë¬¸ì¥']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85358d4a-98fd-4df8-90bc-0ec82aa4821f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS] ì²«ë²ˆì§¸ ë¬¸ì¥ [SEP]', '[CLS] ë‘ë²ˆì§¸ ë¬¸ì¥ [SEP]']\n",
      "['[CLS] ì²«ë²ˆì§¸ ë¬¸ì¥ [SEP] ë‘ë²ˆì§¸ ë¬¸ì¥ [SEP]']\n"
     ]
    }
   ],
   "source": [
    "# batch_decode() ë©”ì„œë“œ ì‚¬ìš© ì‹œ input_ids í† í° ì•„ì´ë””ë¥¼ ë¬¸ìì—´ë¡œ ë³µì› í•  ìˆ˜ ìˆë‹¤.\n",
    "# ê¸°ë³¸ì ìœ¼ë¡œ í† í°í™”ì‹œ CLS ì™€ SEPìœ¼ë¡œ ë‚˜ë‰˜ëŠ”ë° 2ê°œì˜ ë¬¸ì¥ í† í°í™” ì‹œ SEPìœ¼ë¡œ ë‘ ë¬¸ì¥ì„ êµ¬ë¶„í•  ìˆ˜ ìˆë‹¤.\n",
    "first_tokenized_result = tokenizer(['ì²«ë²ˆì§¸ ë¬¸ì¥','ë‘ë²ˆì§¸ ë¬¸ì¥'])['input_ids']\n",
    "print(tokenizer.batch_decode(first_tokenized_result))\n",
    "\n",
    "second_tokenized_result = tokenizer([['ì²«ë²ˆì§¸ ë¬¸ì¥','ë‘ë²ˆì§¸ ë¬¸ì¥']])['input_ids']\n",
    "print(tokenizer.batch_decode(second_tokenized_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9616b9-96cd-425f-8a42-cbfea0a2ae61",
   "metadata": {},
   "source": [
    "- í† í°í™” ê²°ê³¼ ì¤‘ token_type_idsëŠ” ë¬¸ì¥ì„ êµ¬ë¶„í•˜ëŠ” ì—­í• . BERTëŠ” í•™ìŠµ ì‹œ 2ê°œì˜ ë¬¸ì¥ì´ ì„œë¡œ ì´ì–´ì§€ëŠ”ì§€ ë§ì¶”ëŠ” NSP(Next Sentence Prediction)ì‘ì—…ì„ í™œìš©í•˜ëŠ”ë° ì´ë¥¼ ìœ„í•´ ë¬¸ì¥ì„ êµ¬ë¶„í•˜ëŠ” token type idë¥¼ ë§Œë“¤ì—ˆë‹¤.\n",
    "- RoBERTa ê³„ì—´ ëª¨ë¸ì˜ ê²½ìš° NSPì‘ì—…ì„ í•™ìŠµ ê³¼ì •ì—ì„œ ì œê±° í–ˆê¸° ë•Œë¬¸ì— ë¬¸ì¥ í† í° êµ¬ë¶„ì´ í•„ìš”ì—†ë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "119a860b-f113-47d1-9cfd-defdd9281880",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[2, 1656, 2517, 3135, 6265, 3, 864, 2517, 3135, 2346, 2121, 3]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n",
      "{'input_ids': [[0, 1656, 2517, 3135, 6265, 2, 864, 2517, 3135, 2346, 2121, 2]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n",
      "{'input_ids': [[0, 9502, 3645, 2, 2, 10815, 3645, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "bert_tokenizer = AutoTokenizer.from_pretrained('klue/bert-base')\n",
    "print(bert_tokenizer([['ì²«ë²ˆì§¸ ë¬¸ì¥','ë‘ë²ˆì§¸ë¬¸ì¥']]))\n",
    "\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained('klue/roberta-base')\n",
    "print(roberta_tokenizer([['ì²«ë²ˆì§¸ ë¬¸ì¥','ë‘ë²ˆì§¸ë¬¸ì¥']]))\n",
    "\n",
    "en_roberta_tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "print(en_roberta_tokenizer([['first sentence','second sentence']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696e9797-8201-4af6-8d9b-d6e2aca5bdc8",
   "metadata": {},
   "source": [
    "- Attention_maskëŠ” í•´ë‹¹ í† í°ì´ íŒ¨ë”©ì¸ì§€ ì •ë³´ë¥¼ ë‹´ê³  ìˆë‹¤.\n",
    "- íŒ¨ë”©ì€ ëª¨ë¸ì— ì…ë ¥í•˜ëŠ” í† í° ì•„ì´ë””ì˜ ê¸¸ì´ë¥¼ ë§ì¶”ê¸° ìœ„í•´ ì¶”ê°€í•˜ëŠ” íŠ¹ìˆ˜ í† í°ì´ë‹¤\n",
    "- padding ì¸ìì— longestë¥¼ ì¶”ê°€í•˜ë©´ ê¸´ ë¬¸ì¥ì— ë§ì¶° íŒ¨ë”© í† í°ì„ ì¶”ê°€í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c6978c6-1546-4780-b7f9-f286c9456233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[0, 1599, 2073, 6265, 2, 1, 1], [0, 5370, 831, 646, 6265, 28674, 2]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#attention_mask í™•ì¸\n",
    "tokenizer(['ì§§ì€ ë¬¸ì¥','ì´ê±´ ë” ê¸´ ë¬¸ì¥ì´ë‹¤'],padding = 'longest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3d7e3b-4bed-4f33-b3e9-b6d6217feac1",
   "metadata": {},
   "source": [
    "## DataSets í™œìš©í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9e99a2d-9235-4e09-8c3a-2e05e6e441aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095669ba17724d4eada36763fd8576a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/22.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34fddd2d5aa94895bfc0f53021d1c428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/21.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c8fc03f40464704873185c95b5c8368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/8.68M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41043b07d4694bbb9664c79faeac0dc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/17554 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94007c4f809b42e4b7b5beaf9ec6ec6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/5841 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'context', 'news_category', 'source', 'guid', 'is_impossible', 'question_type', 'question', 'answers'],\n",
       "        num_rows: 17554\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['title', 'context', 'news_category', 'source', 'guid', 'is_impossible', 'question_type', 'question', 'answers'],\n",
       "        num_rows: 5841\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "klue_mrc_dataset = load_dataset('klue','mrc')\n",
    "klue_mrc_dataset\n",
    "\n",
    "#ë§Œì•½ì— train(test,validataion)ë°ì´í„°ë§Œ í•„ìš”í•˜ë‹¤ê³  í•˜ë©´ ì•„ë˜ì™€ ê°™ì€ ì½”ë“œ\n",
    "#only_train = load_dataset('klue','mrc','split = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34167c3a-0ca6-4f24-a1f7-a035984dd124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¡œì»¬ì˜ csv ë°ì´í„° í™œìš©í•˜ê¸°\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset('csv',data_files = 'file.csv')\n",
    "#ë”•ì…”ë„ˆë¦¬ ì‚¬ìš©\n",
    "from datasets import Dataset\n",
    "my_dict = {'A' :[1,2,3]}\n",
    "dataset = Dataset.from_dict(my_dict)\n",
    "#íŒë‹¤ìŠ¤ í™œìš©\n",
    "from datasets import Dataset\n",
    "df = pd.DataFrame({'A':[1,2,3]})\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f986f5c-afe4-4be9-95a5-584a531e2e52",
   "metadata": {},
   "source": [
    "## ëª¨ë¸ í•™ìŠµ í•˜ê¸°\n",
    "\n",
    "- í•œêµ­ì–´ ê¸°ì‚¬ ì œëª©ìœ¼ë¡œ ê¸°ì‚¬ì˜ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜í•˜ëŠ” ëª¨ë¸ ë§Œë“¤ê¸°\n",
    "- HuggingFace Transformerì—ì„œëŠ” í•™ìŠµ ê³¼ì •ì„ ì¶”ìƒí™”í•œ Trainer APIë¥¼ ì œê³µí•œë‹¤. ì´ë¥¼ ì‚¬ìš©í•˜ë©´ í•™ìŠµì„ ê°„í¸í•˜ê²Œ í•  ìˆ˜ ìˆì§€ë§Œ,ë‚´ë¶€ì—ì„œ ì–´ë–¤ ê³¼ì •ì„ ê±°ì¹˜ëŠ”ì§€ ì•Œê¸° ì–´ë µë‹¤ëŠ” ë‹¨ì ë„ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d66b95f-64ef-4b21-aead-461236a118f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f0beed4d0b8446186e69cd3e1b3394c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/4.17M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54a235d0d284369b0456086e30bbd09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/847k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6773db80b62c4e34b27f0fd55ea3eece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/45678 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81a11a497994ea788935b057aa8de70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/9107 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'guid': 'ynat-v1_train_00000',\n",
       " 'title': 'ìœ íŠœë¸Œ ë‚´ë‹¬ 2ì¼ê¹Œì§€ í¬ë¦¬ì—ì´í„° ì§€ì› ê³µê°„ ìš´ì˜',\n",
       " 'label': 3,\n",
       " 'url': 'https://news.naver.com/main/read.nhn?mode=LS2D&mid=shm&sid1=105&sid2=227&oid=001&aid=0008508947',\n",
       " 'date': '2016.06.30. ì˜¤ì „ 10:36'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ë°ì´í„° ì…‹ ì¤€ë¹„\n",
    "klue_tc_train = load_dataset('klue','ynat',split = 'train')\n",
    "klue_tc_eval = load_dataset('klue','ynat',split = 'validation')\n",
    "klue_tc_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b50f616-beb2-4e0f-bd0a-e6a7a0937289",
   "metadata": {},
   "source": [
    "guid : ë°ì´í„°ì˜ ê³ ìœ  id\n",
    "\n",
    "\n",
    "title : ë‰´ìŠ¤ ì œëª©\n",
    "\n",
    "label : ì†í•œ ì¹´í…Œê³ ë¦¬ ID\n",
    "\n",
    "url : ë‰´ìŠ¤ ë§í¬\n",
    "\n",
    "date : ë‰´ìŠ¤ ì…ë ¥ ì‹œê°„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c7a45a0-5231-48ce-a109-e219932420a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ITê³¼í•™', 'ê²½ì œ', 'ì‚¬íšŒ', 'ìƒí™œë¬¸í™”', 'ì„¸ê³„', 'ìŠ¤í¬ì¸ ', 'ì •ì¹˜']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_tc_train.features['label'].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13153af2-d815-45b7-adc7-180a42defb8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b229ea18cc404ca18936ae058609c0bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/45678 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'title': 'ìœ íŠœë¸Œ ë‚´ë‹¬ 2ì¼ê¹Œì§€ í¬ë¦¬ì—ì´í„° ì§€ì› ê³µê°„ ìš´ì˜', 'label': 3, 'label_str': 'ìƒí™œë¬¸í™”'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë¶ˆí•„ìš” í–‰ ì œê±°\n",
    "klue_tc_train = klue_tc_train.remove_columns(['guid','url','date'])\n",
    "klue_tc_eval = klue_tc_eval.remove_columns(['guid','url','date'])\n",
    "# ë ˆì´ë¸” ì¹´í…Œê³ ë¦¬ ì—´ ì¶”ê°€\n",
    "klue_tc_label = klue_tc_train.features['label']\n",
    "def make_label(batch):\n",
    "    batch['label_str'] = klue_tc_label.int2str(batch['label'])\n",
    "    return batch\n",
    "klue_tc_train = klue_tc_train.map(make_label,batched=True,batch_size = 1000)\n",
    "klue_tc_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4357a7a-164d-4ac0-a647-75ab3bf6ff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10,000ê°œë§Œ ê°€ì§€ê³  í•´ë³´ì\n",
    "train_dataset = klue_tc_train.train_test_split(test_size=10000 , shuffle = True)['test']\n",
    "dataset = klue_tc_eval.train_test_split(test_size=1000, shuffle = True)\n",
    "test_dataset = dataset['test']\n",
    "valid_dataset = dataset['train'].train_test_split(test_size=1000,shuffle=True)['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7137ac87-e46b-4f81-a472-29ad89fe9b19",
   "metadata": {},
   "source": [
    "\n",
    "## Trainer API ì‚¬ìš©í•˜ê¸°\n",
    "\n",
    "- í•™ìŠµì— í•„ìš”í•œ ë‹¤ì–‘í•œ ê¸°ëŠ¥(ë°ì´í„°ë¡œë”,ë¡œê¹…,í‰ê°€,ì €ì¥)ì„ TrainingArgumentsë§Œìœ¼ë¡œ ì‰½ê²Œ í™œìš©í•  ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afafb520-3ec2-4fb1-a870-028044c4d312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ktaek\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abdd011da17c4f609d1762a521913e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c3bb29132bb4698810ef158192db093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c935c2cc624243ad7a88ace56ce473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ktaek\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\ktaek\\anaconda3\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:370: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 13:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.569300</td>\n",
       "      <td>0.497314</td>\n",
       "      <td>0.849000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 00:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5668138265609741,\n",
       " 'eval_Accuracy': 0.831,\n",
       " 'eval_runtime': 26.5605,\n",
       " 'eval_samples_per_second': 37.65,\n",
       " 'eval_steps_per_second': 4.706,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import (Trainer, TrainingArguments, AutoModelForSequenceClassification, AutoTokenizer)\n",
    "def tokenizer_function(examples):\n",
    "    return tokenizer(examples['title'],padding='max_length',truncation=True)\n",
    "model_id = 'klue/roberta-base'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels = len(train_dataset.features['label'].names))\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "train_dataset = train_dataset.map(tokenizer_function,batched=True)\n",
    "valid_dataset = valid_dataset.map(tokenizer_function,batched=True)\n",
    "test_dataset = test_dataset.map(tokenizer_function,batched=True)\n",
    "\n",
    "#í•™ìŠµì´ ëë‚  ë•Œë§ˆë‹¤ ê²€ì¦ ë°ì´í„° í‰ê°€ê°€ ì´ë£¨ì–´ ì§€ë„ë¡ evaluation_strategy = epochìœ¼ë¡œ ì„¤ì •\n",
    "#í•™ìŠµì´ ì˜ ì´ë£¨ì–´ ì§€ëŠ”ì§€ í™•ì¸í•  ë•Œ ì‚¬ìš©í•  í‰ê°€ì§€í‘œ ì •ì˜. ì˜ˆì¸¡ ê²°ê³¼ì¸ eval_predë¥¼ ì…ë ¤ê¸ë¡œ ë°›ì•„ ì˜ˆì¸¡ ê²°ê³¼ ì¤‘ ê°€ì¥ í° ê°’ì„ ê°–ëŠ” í´ë˜ìŠ¤ë¥¼ np.argmaxë¡œ ë½‘ì•„ predictions ë³€ìˆ˜ì— ì €ì¥í•˜ê³  labelsì™€ ê°™ì€ ê°’ì„ ê°–ëŠ” ê²°ê³¼ ë¹„ìœ¨ì„ ì •í™•ë„ë¡œ ë°˜í™˜\n",
    "training_args = TrainingArguments(\n",
    "    output_dir= \"./result\",\n",
    "    num_train_epochs = 1,\n",
    "    per_device_train_batch_size = 8,\n",
    "    per_device_eval_batch_size = 8,\n",
    "    evaluation_strategy = 'epoch',\n",
    "    learning_rate = 5e-5,\n",
    "    push_to_hub = False)\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    prediction = np.argmax(logits,axis = -1)\n",
    "    return {'Accuracy' : (prediction==labels).mean()}\n",
    "\n",
    "#í•™ìŠµ ì§„í–‰í•˜ê¸°\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab56f3d-d895-436e-9f34-94c1f89bf987",
   "metadata": {},
   "source": [
    "## Trainer API ì—†ì´ í•™ìŠµí•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45fe279c-c389-48ab-87ff-33183c9a4990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í•™ìŠµì— ì‚¬ìš©í•  ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ì¤€ë¹„\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "\n",
    "# title í† í°í™”\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['title'],padding='max_length',truncation=True)\n",
    "#ëª¨ë¸,í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_id = 'klue/roberta-base'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id,num_labels = len(train_dataset.features['label'].names))\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf0855c-6501-4332-88eb-dc8e962e490a",
   "metadata": {},
   "source": [
    "1. model.train()ìœ¼ë¡œ ëª¨ë¸ì„ í•™ìŠµëª¨ë“œë¡œ ì „í™˜\n",
    "2. ë°°ì¹˜ ë°ì´í„°ë¥¼ ê°€ì§€ê³ ì™€ì„œ ëª¨ë¸ì— ì…ë ¥ìœ¼ë¡œ ì „ë‹¬(input_ids,attention_mask,ì •ë‹µë ˆì´ë¸” labels)\n",
    "3. ë ˆì´ë¸”ê³¼ì˜ ì°¨ì´ë¥¼ í†µí•´ ê³„ì‚°ëœ lossê°’ìœ¼ë¡œ ì—­ì „íŒŒ ìˆ˜í–‰í•˜ê³ , ì˜µí‹°ë§ˆì´ì €ì˜ step í˜¸ì¶œë¡œ ì—­ì „íŒŒ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ëª¨ë¸ ì—…ë°ì´íŠ¸\n",
    "4. total_lossì˜ ê²½ìš° í•™ìŠµì´ ì˜ë˜ê³  ìˆëŠ”ì§€ ì§‘ê²Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f70226b8-057f-4fd2-a8aa-5c92b808eba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47feebfad4f4e4aabd48db56e968ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#í•™ìŠµ ë°ì´í„° ì¤€ë¹„\n",
    "def make_dataloader(dataset, batch_size, shuffle=True):\n",
    "    dataset = dataset.map(tokenize_function,batched=True).with_format('torch')\n",
    "    dataset = dataset.rename_column('label','labels')\n",
    "    dataset = dataset.remove_columns(column_names = ['title'])\n",
    "    return DataLoader(dataset,batch_size = batch_size, shuffle = shuffle)\n",
    "train_dataloader = make_dataloader(train_dataset,batch_size = 8, shuffle=True)\n",
    "valid_dataloader = make_dataloader(valid_dataset,batch_size = 8, shuffle=False)\n",
    "test_dataloader = make_dataloader(test_dataset,batch_size = 8, shuffle=False)\n",
    "\n",
    "#í•™ìŠµ í•¨ìˆ˜\n",
    "def train_epoch(model, data_loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids,attention_mask=attention_mask,labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss +=loss.item()\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "516bc3bb-2ce6-4a8b-9895-e6cc2e54c3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19350ab451c84a69a33eb0c4e37825ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss : 0.6234439497977495\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30ee91aa33140e483605db807d8baba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validataion Loss : 0.573597308754921\n",
      "Validataion Accuracy : 0.817\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b452fdaf56c7414fa273a035e7eaef6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.793\n"
     ]
    }
   ],
   "source": [
    "# í‰ê°€ í•¨ìˆ˜ ì •ì˜\n",
    "def evaluate(model,data_loader):\n",
    "    model.eval()\n",
    "    total_loss=0\n",
    "    predictions=[]\n",
    "    true_labels=[]\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids,attention_mask=attention_mask,labels=labels)\n",
    "            logits = outputs.logits\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(logits,dim=-1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    avg_loss = total_loss/len(data_loader)\n",
    "    accuracy = np.mean(np.array(predictions) == np.array(true_labels))\n",
    "    return avg_loss,accuracy\n",
    "# í•™ìŠµ ë£¨í”„ ìˆ˜í–‰í•˜ê¸°\n",
    "num_epochs = 1\n",
    "optimizer = AdamW(model.parameters(),lr=5e-5)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    train_loss = train_epoch(model,train_dataloader,optimizer)\n",
    "    print(f'Training loss : {train_loss}')\n",
    "    valid_loss, valid_accuracy = evaluate(model, valid_dataloader)\n",
    "    print(f\"Validataion Loss : {valid_loss}\")\n",
    "    print(f\"Validataion Accuracy : {valid_accuracy}\")\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "_,test_accuracy = evaluate(model,test_dataloader)\n",
    "print(f'Test Accuracy : {test_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67927b25-b8e7-4f7f-bb4a-a8bfa465c984",
   "metadata": {},
   "source": [
    "### í•™ìŠµ ëª¨ë¸ í—ˆê¹…í˜ì´ìŠ¤ ì—…ë¡œë“œ\n",
    "- ì—…ë¡œë“œ ë°©ë²•ì€ í¬ê²Œ Trainer ì‚¬ìš©í–ˆì„ ë•Œ, ì‚¬ìš©í•˜ì§€ ì•Šì•˜ì„ ë•Œë¡œ ë‚˜ë‰¨\n",
    "- Trainer ì‚¬ìš©í•œ ê²½ìš°  trainer ì¸ìŠ¤í„´ìŠ¤ì—ì„œ push_to_hub() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ë©´ í•™ìŠµí•œ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ í•¨ê»˜ ëª¨ë¸ í—ˆë¸Œì— ì—…ë¡œë“œí•œë‹¤\n",
    "- ì§ì ‘ í•™ìŠµí•œ ê²½ìš° ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ê°ê° push_to_hub()ë¡œ ì—…ë¡œë“œ í•  ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c10df6c-0eca-4690-8e59-ca778a0202e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "09c4c57f-0d66-4cb0-a856-14387efe3f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to C:\\Users\\ktaek\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69efcd8b1f4940ae8125501894f1ae97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93a7978e76af46c3a0c4a38884128bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1728727849.DESKTOP-340AC9K.21016.0:   0%|          | 0.00/6.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39f30164ee34cdda8410726596f2ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b6b61dfde1841e194933d21a2ba08a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1728728705.DESKTOP-340AC9K.21016.1:   0%|          | 0.00/411 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23dde06485b04a2daefb4f49b4df41d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70f5ba2fd4f14b2a8a28ace2da019285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "679b0ec3be4f49c2babf19190892c5b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/ktaek94/roberta-base-klue-ynat-classification/commit/f91083419f86288b66322d56ca66fccce74a3243', commit_message='Upload tokenizer', commit_description='', oid='f91083419f86288b66322d56ca66fccce74a3243', pr_url=None, repo_url=RepoUrl('https://huggingface.co/ktaek94/roberta-base-klue-ynat-classification', endpoint='https://huggingface.co', repo_type='model', repo_id='ktaek94/roberta-base-klue-ynat-classification'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token = '---')\n",
    "repo_id = f\"ktaek94/roberta-base-klue-ynat-classification\"\n",
    "#Trainerì‚¬ìš©ì‹œ\n",
    "trainer.push_to_hub(repo_id)\n",
    "#ì§ì ‘ í•™ìŠµ ì‹œ\n",
    "model.push_to_hub(repo_id)\n",
    "tokenizer.push_to_hub(repo_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebf4342-4e82-49c8-9a10-b55a3e054fb2",
   "metadata": {},
   "source": [
    "## ëª¨ë¸ ì¶”ë¡ í•˜ê¸°\n",
    "- ëª¨ë¸ì„ í™œìš©í•˜ê¸° ì‰½ë„ë¡ ì¶”ìƒí™”í•œ íŒŒì´í”„ë¼ì¸ì„ í™œìš©í•˜ëŠ” ë°©ë²•\n",
    "- ì§ì ‘ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¶ˆëŸ¬ì™€ í™œìš©í•˜ëŠ” ë°©ë²•\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1cae3b-969c-4eb9-a5e1-bed37274b72b",
   "metadata": {},
   "source": [
    "### íŒŒì´í”„ë¼ì¸ í™œìš©í•œ ì¶”ë¡ \n",
    "- í† í¬ë‚˜ì´ì €ì™€ ëª¨ë¸ì„ ê²°í•©í•´ ë°ì´í„°ì˜ ì „í›„ì²˜ë¦¬ì™€ ëª¨ë¸ ì¶”ë¡ ì„ ê°„ë‹¨í•˜ê²Œ ìˆ˜í–‰í•˜ëŠ” pipelineì„ ì œê³µí•œë‹¤.\n",
    "- íŒŒì´í”„ë¼ì¸ì€ í¬ê²Œ ì‘ì—… ì¢…ë¥˜,ëª¨ë¸, ì„¤ì •ì„ ì…ë ¥ìœ¼ë¡œ ë°›ëŠ”ë‹¤. ì‘ì—… ì¢…ë¥˜ëŠ” í…ìŠ¤íŠ¸ ë¶„ë¥˜,í† í° ë¶„ë¥˜ ë“± ì‘ì—…ì— ë§ì¶° ì„¤ì •í•˜ê³  ëª¨ë¸ì— ì €ì¥ì†Œ ì•„ì´ë””ë¥¼ ì„¤ì •í•˜ë©´ëœë‹¤.\n",
    "- ìì„¸í•œ ì„¤ëª…ì€ huggingface.co/docs/transformers/main_classes/pipelines#transformers.pipeline.configì—ì„œ í™•ì¸ ê°€ëŠ¥í•˜ë‹¤\n",
    "- ì¶”ë¡ í•˜ê³ ì í•˜ëŠ” í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ë©´ ë ˆì´ë¸”ê³¼ ê·¸ í™•ë¥ ì„ ë°˜í™˜í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8f269aca-0f72-4315-bafe-9ccea17a668e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ë¬´ëŠ¬ë§Œ êµ­ì‚° OEM ìˆ˜ì…ì°¨ íŒë§¤ ë°˜ë“±ì„¸â€¦ì°¨ì¢…ë„ ë‹¤ì–‘í™”',\n",
       " 'ì‚¬ìš°ë”” ì›ìœ  ê³µê¸‰ ë¶€ì¡±í•œê°€â€¦ç¾ ì¦ì‚°ìš”êµ¬ì— ì´ì˜',\n",
       " 'ê²Œì‹œíŒ KBS ì•ˆì „í•œ ëŒ€í•œë¯¼êµ­ ì£¼ê°„ íŠ¹ë³„í¸ì„±',\n",
       " 'ì´ì–¸ì£¼ ì°¸ì „ëª…ì˜ˆìˆ˜ë‹¹ êµ­ë¯¼ì—°ê¸ˆ í‰ê·  20%ê¹Œì§€ ì¸ìƒë²• ë°œì˜',\n",
       " 'ì•ˆì‚°ì†Œì‹ ë””ë”¤ëŒ ì¼ìë¦¬ ì‚¬ì—… ì°¸ì—¬ì 37ëª… ëª¨ì§‘']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['title'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8f2d9c2e-15e8-4f56-aa3a-d3ae52a6b056",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9278706908226013},\n",
       " {'label': 'LABEL_4', 'score': 0.9798926115036011},\n",
       " {'label': 'LABEL_3', 'score': 0.7625777721405029},\n",
       " {'label': 'LABEL_1', 'score': 0.8380774259567261},\n",
       " {'label': 'LABEL_2', 'score': 0.781562328338623}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "model_id = 'ktaek94/roberta-base-klue-ynat-classification'\n",
    "model_pipeline = pipeline('text-classification',model=model_id)\n",
    "model_pipeline(dataset['train']['title'][:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8290fba1-c767-4bd5-8b08-744d362ba3ae",
   "metadata": {},
   "source": [
    "### ì§ì ‘ ì¶”ë¡ \n",
    "- ì§ì ‘ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¶ˆëŸ¬ì™€ ì¶”ë¡ ì„ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤.\n",
    "- __init__ ë©”ì„œë“œì—ì„œ ì…ë ¥ë°›ì€ ëª¨ë¸ ì•„ì´ë””ì— ë§ëŠ” ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¶ˆëŸ¬ì˜¨ë‹¤.\n",
    "- Custompipelineì˜ ì¸ìŠ¤í„´ìŠ¤ë¥¼ í˜¸ì¶œ í• ë•Œ __call__ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ëŠ”ë° tokenizerë¥¼ í†µí•´ í† í°í™”ë¥¼ ìˆ˜í–‰\n",
    "- ëª¨ë¸ ì¶”ë¡ ì„ ìˆ˜í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a71b69d7-633e-4c36-9c41-152d58049a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9278706908226013},\n",
       " {'label': 'LABEL_4', 'score': 0.9798926115036011},\n",
       " {'label': 'LABEL_3', 'score': 0.7625780701637268},\n",
       " {'label': 'LABEL_1', 'score': 0.8380774259567261},\n",
       " {'label': 'LABEL_2', 'score': 0.781562328338623}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "class CustomPipeline:\n",
    "    def __init__(self,model_id):\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_id)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "        self.model.eval()\n",
    "    def __call__(self,texts):\n",
    "        tokenized = self.tokenizer(texts, return_tensors = 'pt', padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**tokenized)\n",
    "            logits = outputs.logits\n",
    "        probabilities = softmax(logits, dim = -1)\n",
    "        scores, labels = torch.max(probabilities, dim = -1)\n",
    "        labels_str = [self.model.config.id2label[label_idx] for label_idx in labels.tolist()]\n",
    "        return [{'label' :label,'score':score.item()} for label, score in zip(labels_str,scores)]\n",
    "custom_pipeline = CustomPipeline(model_id)\n",
    "custom_pipeline(dataset['train']['title'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca5ca1a-9f46-4c7b-80f8-bfb58dc2ab50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
