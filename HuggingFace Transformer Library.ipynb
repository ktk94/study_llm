{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c964b04b-2996-4fe7-a186-04a544afd199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c068b291-3363-4b07-8fb7-9a38a0da244c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ImportError: Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U 해결\n",
    "#! pip install -U accelerate\n",
    "#! pip install -U transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf2d594-7184-449a-9beb-4ed1a8bd586e",
   "metadata": {},
   "source": [
    "#### 허깅페이스 트랜스포머 활용 라이브러리사용 시 \n",
    "!pip install transformers==4.40.1 datasets==2.19.0 huggingface_hub==0.23.0 -qq\n",
    "\n",
    "- huggingface transformer 라이브러리 사용하면 허깅페이스 모델 허브의 모델을 쉽게 불러와 사용가능\n",
    "- **꼭 알아야 하는 사실은 huggingface는 모델을 body와 head로 구분한다. 이유는 같은 바디를 사용하면서 다른 작업에 사용할 수 있도록 만들기 위해서다**\n",
    "- 모델의 바디만 불러올 수 있고, 헤드와 함께 불러올 수도 있다.\n",
    "- 허깅페이스 모델을 저장할 때 config.json 파일이 함께 저장되는데,해당 설정 파일에는 **모델의 종류,설정 파라미터,어휘 사전 크기,토크나이저 클래스 등**이 저장된다. 이를 참고해서 AutoModel,AutoTokenizer 는 적절한 모델과 토크나이저를 불러옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "927e38e3-dcc7-407c-9057-f59f81fdb615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "## 모델 바디 불러오기\n",
    "from transformers import AutoModel\n",
    "model_id = 'klue/roberta-base'\n",
    "model= AutoModel.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e082db-ae4d-4b80-9aef-5a32b9fd9da8",
   "metadata": {},
   "source": [
    "AutoModelForSequenceClassification은 텍스트 시퀀스 분류를 위한 헤드가 포함된 모델을 불러올 때 사용하는 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07104f58-5dd5-4f51-99bf-1d8c8ef918e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 텍스트 분류 헤드가 붙은 모델 불러오기\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "model_id = 'SamLowe/roberta-base-go_emotions'\n",
    "classification_model = AutoModelForSequenceClassification.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9d33cd-de13-4932-8bd5-03955a18c733",
   "metadata": {},
   "source": [
    "### 허깅 페이스로 불러온 모델의 저장 경로\n",
    "~/.cache/huggingface/transformers/\n",
    "\n",
    "- AutoConfig 를 활용하면 모델의 특성을 확인 할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a73dc0a-2acd-4de6-82d1-9f9369009797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaConfig {\n",
      "  \"_name_or_path\": \"klue/roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "config = AutoConfig.from_pretrained(\"klue/roberta-base\")\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9789e269-ed5a-4e71-8988-dda9ad1cb9bf",
   "metadata": {},
   "source": [
    "### 토크나이저 \n",
    "- 토크나이저는 텍스트를 토큰 단위로 나누고 각 토큰을 대응 하는 토큰 아이디로 변환하거나 필요의 경우 특수 토큰을 추가하는 역할도 한다.\n",
    "- AutoTokenizer 클래스를 이용해 토크나이저를 불러올 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "887cecc9-1c5d-42e7-bd1f-fed504ff5fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_id = 'klue/roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1c09651-fde1-461e-ba8a-7b9010c018cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [0, 9157, 7461, 2190, 2259, 8509, 2138, 1793, 2855, 5385, 2200, 4835, 2088, 1793, 2855, 15129, 2200, 15070, 2205, 9253, 5177, 1793, 2855, 4140, 4008, 2069, 3605, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "['[CLS]', '토크', '##나이', '##저', '##는', '텍스트', '##를', '토', '##큰', '단위', '##로', '나누', '##고', '토', '##큰', '아이디', '##로', '변환', '##하', '##거나', '특수', '토', '##큰', '추가', '역할', '##을', '한다', '[SEP]']\n",
      "[CLS] 토크나이저는 텍스트를 토큰 단위로 나누고 토큰 아이디로 변환하거나 특수 토큰 추가 역할을 한다 [SEP]\n",
      "토크나이저는 텍스트를 토큰 단위로 나누고 토큰 아이디로 변환하거나 특수 토큰 추가 역할을 한다\n"
     ]
    }
   ],
   "source": [
    "#토크나이저 사용해보기\n",
    "tokenized = tokenizer('토크나이저는 텍스트를 토큰 단위로 나누고 토큰 아이디로 변환하거나 특수 토큰 추가 역할을 한다')\n",
    "print(tokenized)\n",
    "\n",
    "print(tokenizer.convert_ids_to_tokens(tokenized['input_ids']))\n",
    "\n",
    "print(tokenizer.decode(tokenized['input_ids']))\n",
    "\n",
    "print(tokenizer.decode(tokenized['input_ids'],skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cdc649-77c4-4d3b-af63-69950c472db3",
   "metadata": {},
   "source": [
    "- input_ids는 토큰화 했을 때 각 토큰이 토크나이저 사전의 몇번째 항목인지 나타낸다.\n",
    "- 첫번째 항목은 0 인데 이는 [CLS] 토큰으로 대응된다.\n",
    "- attention_mask가 1이면 padding token이 아닌 실제 토큰을 의미함.\n",
    "- token_type_ids가 0 이면 일반적으로 첫번째 문장을 의미한다.\n",
    "- 토큰 아이디를 다시 텍스트로 돌리고 싶다면 토크나이저의 decode 메서드를 사용하고, 만약 [CLS] 나 [SEP] 과 같은 특수 토큰을 제외하고싶으면 skip_special_tokens 인자를 True로 설정하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a0cac48-2f32-4968-ae03-effca85399dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[0, 1656, 2517, 3135, 6265, 2], [0, 864, 2517, 3135, 6265, 2]], 'token_type_ids': [[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]}\n",
      "{'input_ids': [[0, 1656, 2517, 3135, 6265, 2, 864, 2517, 3135, 6265, 2]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "# 여러개 문장 처리하기\n",
    "print(tokenizer(['첫번째 문장','두번째 문장']))\n",
    "# 2개의 문장이 한번에 모델에 입력되길 원하면 리스트로 묶어야\n",
    "print(tokenizer([['첫번째 문장','두번째 문장']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85358d4a-98fd-4df8-90bc-0ec82aa4821f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS] 첫번째 문장 [SEP]', '[CLS] 두번째 문장 [SEP]']\n",
      "['[CLS] 첫번째 문장 [SEP] 두번째 문장 [SEP]']\n"
     ]
    }
   ],
   "source": [
    "# batch_decode() 메서드 사용 시 input_ids 토큰 아이디를 문자열로 복원 할 수 있다.\n",
    "# 기본적으로 토큰화시 CLS 와 SEP으로 나뉘는데 2개의 문장 토큰화 시 SEP으로 두 문장을 구분할 수 있다.\n",
    "first_tokenized_result = tokenizer(['첫번째 문장','두번째 문장'])['input_ids']\n",
    "print(tokenizer.batch_decode(first_tokenized_result))\n",
    "\n",
    "second_tokenized_result = tokenizer([['첫번째 문장','두번째 문장']])['input_ids']\n",
    "print(tokenizer.batch_decode(second_tokenized_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9616b9-96cd-425f-8a42-cbfea0a2ae61",
   "metadata": {},
   "source": [
    "- 토큰화 결과 중 token_type_ids는 문장을 구분하는 역할. BERT는 학습 시 2개의 문장이 서로 이어지는지 맞추는 NSP(Next Sentence Prediction)작업을 활용하는데 이를 위해 문장을 구분하는 token type id를 만들었다.\n",
    "- RoBERTa 계열 모델의 경우 NSP작업을 학습 과정에서 제거 했기 때문에 문장 토큰 구분이 필요없다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "119a860b-f113-47d1-9cfd-defdd9281880",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[2, 1656, 2517, 3135, 6265, 3, 864, 2517, 3135, 2346, 2121, 3]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n",
      "{'input_ids': [[0, 1656, 2517, 3135, 6265, 2, 864, 2517, 3135, 2346, 2121, 2]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n",
      "{'input_ids': [[0, 9502, 3645, 2, 2, 10815, 3645, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "bert_tokenizer = AutoTokenizer.from_pretrained('klue/bert-base')\n",
    "print(bert_tokenizer([['첫번째 문장','두번째문장']]))\n",
    "\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained('klue/roberta-base')\n",
    "print(roberta_tokenizer([['첫번째 문장','두번째문장']]))\n",
    "\n",
    "en_roberta_tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "print(en_roberta_tokenizer([['first sentence','second sentence']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696e9797-8201-4af6-8d9b-d6e2aca5bdc8",
   "metadata": {},
   "source": [
    "- Attention_mask는 해당 토큰이 패딩인지 정보를 담고 있다.\n",
    "- 패딩은 모델에 입력하는 토큰 아이디의 길이를 맞추기 위해 추가하는 특수 토큰이다\n",
    "- padding 인자에 longest를 추가하면 긴 문장에 맞춰 패딩 토큰을 추가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c6978c6-1546-4780-b7f9-f286c9456233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[0, 1599, 2073, 6265, 2, 1, 1], [0, 5370, 831, 646, 6265, 28674, 2]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#attention_mask 확인\n",
    "tokenizer(['짧은 문장','이건 더 긴 문장이다'],padding = 'longest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3d7e3b-4bed-4f33-b3e9-b6d6217feac1",
   "metadata": {},
   "source": [
    "## DataSets 활용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9e99a2d-9235-4e09-8c3a-2e05e6e441aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095669ba17724d4eada36763fd8576a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/22.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34fddd2d5aa94895bfc0f53021d1c428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/21.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c8fc03f40464704873185c95b5c8368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/8.68M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41043b07d4694bbb9664c79faeac0dc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/17554 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94007c4f809b42e4b7b5beaf9ec6ec6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/5841 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'context', 'news_category', 'source', 'guid', 'is_impossible', 'question_type', 'question', 'answers'],\n",
       "        num_rows: 17554\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['title', 'context', 'news_category', 'source', 'guid', 'is_impossible', 'question_type', 'question', 'answers'],\n",
       "        num_rows: 5841\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "klue_mrc_dataset = load_dataset('klue','mrc')\n",
    "klue_mrc_dataset\n",
    "\n",
    "#만약에 train(test,validataion)데이터만 필요하다고 하면 아래와 같은 코드\n",
    "#only_train = load_dataset('klue','mrc','split = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34167c3a-0ca6-4f24-a1f7-a035984dd124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로컬의 csv 데이터 활용하기\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset('csv',data_files = 'file.csv')\n",
    "#딕셔너리 사용\n",
    "from datasets import Dataset\n",
    "my_dict = {'A' :[1,2,3]}\n",
    "dataset = Dataset.from_dict(my_dict)\n",
    "#판다스 활용\n",
    "from datasets import Dataset\n",
    "df = pd.DataFrame({'A':[1,2,3]})\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f986f5c-afe4-4be9-95a5-584a531e2e52",
   "metadata": {},
   "source": [
    "## 모델 학습 하기\n",
    "\n",
    "- 한국어 기사 제목으로 기사의 카테고리 분류하는 모델 만들기\n",
    "- HuggingFace Transformer에서는 학습 과정을 추상화한 Trainer API를 제공한다. 이를 사용하면 학습을 간편하게 할 수 있지만,내부에서 어떤 과정을 거치는지 알기 어렵다는 단점도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d66b95f-64ef-4b21-aead-461236a118f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f0beed4d0b8446186e69cd3e1b3394c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/4.17M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54a235d0d284369b0456086e30bbd09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/847k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6773db80b62c4e34b27f0fd55ea3eece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/45678 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81a11a497994ea788935b057aa8de70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/9107 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'guid': 'ynat-v1_train_00000',\n",
       " 'title': '유튜브 내달 2일까지 크리에이터 지원 공간 운영',\n",
       " 'label': 3,\n",
       " 'url': 'https://news.naver.com/main/read.nhn?mode=LS2D&mid=shm&sid1=105&sid2=227&oid=001&aid=0008508947',\n",
       " 'date': '2016.06.30. 오전 10:36'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터 셋 준비\n",
    "klue_tc_train = load_dataset('klue','ynat',split = 'train')\n",
    "klue_tc_eval = load_dataset('klue','ynat',split = 'validation')\n",
    "klue_tc_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b50f616-beb2-4e0f-bd0a-e6a7a0937289",
   "metadata": {},
   "source": [
    "guid : 데이터의 고유 id\n",
    "\n",
    "\n",
    "title : 뉴스 제목\n",
    "\n",
    "label : 속한 카테고리 ID\n",
    "\n",
    "url : 뉴스 링크\n",
    "\n",
    "date : 뉴스 입력 시간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c7a45a0-5231-48ce-a109-e219932420a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IT과학', '경제', '사회', '생활문화', '세계', '스포츠', '정치']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_tc_train.features['label'].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13153af2-d815-45b7-adc7-180a42defb8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b229ea18cc404ca18936ae058609c0bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/45678 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'title': '유튜브 내달 2일까지 크리에이터 지원 공간 운영', 'label': 3, 'label_str': '생활문화'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 불필요 행 제거\n",
    "klue_tc_train = klue_tc_train.remove_columns(['guid','url','date'])\n",
    "klue_tc_eval = klue_tc_eval.remove_columns(['guid','url','date'])\n",
    "# 레이블 카테고리 열 추가\n",
    "klue_tc_label = klue_tc_train.features['label']\n",
    "def make_label(batch):\n",
    "    batch['label_str'] = klue_tc_label.int2str(batch['label'])\n",
    "    return batch\n",
    "klue_tc_train = klue_tc_train.map(make_label,batched=True,batch_size = 1000)\n",
    "klue_tc_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4357a7a-164d-4ac0-a647-75ab3bf6ff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10,000개만 가지고 해보자\n",
    "train_dataset = klue_tc_train.train_test_split(test_size=10000 , shuffle = True)['test']\n",
    "dataset = klue_tc_eval.train_test_split(test_size=1000, shuffle = True)\n",
    "test_dataset = dataset['test']\n",
    "valid_dataset = dataset['train'].train_test_split(test_size=1000,shuffle=True)['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7137ac87-e46b-4f81-a472-29ad89fe9b19",
   "metadata": {},
   "source": [
    "\n",
    "## Trainer API 사용하기\n",
    "\n",
    "- 학습에 필요한 다양한 기능(데이터로더,로깅,평가,저장)을 TrainingArguments만으로 쉽게 활용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afafb520-3ec2-4fb1-a870-028044c4d312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ktaek\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abdd011da17c4f609d1762a521913e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c3bb29132bb4698810ef158192db093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c935c2cc624243ad7a88ace56ce473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ktaek\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\ktaek\\anaconda3\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:370: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 13:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.569300</td>\n",
       "      <td>0.497314</td>\n",
       "      <td>0.849000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 00:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5668138265609741,\n",
       " 'eval_Accuracy': 0.831,\n",
       " 'eval_runtime': 26.5605,\n",
       " 'eval_samples_per_second': 37.65,\n",
       " 'eval_steps_per_second': 4.706,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import (Trainer, TrainingArguments, AutoModelForSequenceClassification, AutoTokenizer)\n",
    "def tokenizer_function(examples):\n",
    "    return tokenizer(examples['title'],padding='max_length',truncation=True)\n",
    "model_id = 'klue/roberta-base'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels = len(train_dataset.features['label'].names))\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "train_dataset = train_dataset.map(tokenizer_function,batched=True)\n",
    "valid_dataset = valid_dataset.map(tokenizer_function,batched=True)\n",
    "test_dataset = test_dataset.map(tokenizer_function,batched=True)\n",
    "\n",
    "#학습이 끝날 때마다 검증 데이터 평가가 이루어 지도록 evaluation_strategy = epoch으로 설정\n",
    "#학습이 잘 이루어 지는지 확인할 때 사용할 평가지표 정의. 예측 결과인 eval_pred를 입려긍로 받아 예측 결과 중 가장 큰 값을 갖는 클래스를 np.argmax로 뽑아 predictions 변수에 저장하고 labels와 같은 값을 갖는 결과 비율을 정확도로 반환\n",
    "training_args = TrainingArguments(\n",
    "    output_dir= \"./result\",\n",
    "    num_train_epochs = 1,\n",
    "    per_device_train_batch_size = 8,\n",
    "    per_device_eval_batch_size = 8,\n",
    "    evaluation_strategy = 'epoch',\n",
    "    learning_rate = 5e-5,\n",
    "    push_to_hub = False)\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    prediction = np.argmax(logits,axis = -1)\n",
    "    return {'Accuracy' : (prediction==labels).mean()}\n",
    "\n",
    "#학습 진행하기\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab56f3d-d895-436e-9f34-94c1f89bf987",
   "metadata": {},
   "source": [
    "## Trainer API 없이 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45fe279c-c389-48ab-87ff-33183c9a4990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습에 사용할 모델과 토크나이저 준비\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "\n",
    "# title 토큰화\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['title'],padding='max_length',truncation=True)\n",
    "#모델,토크나이저 불러오기\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_id = 'klue/roberta-base'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id,num_labels = len(train_dataset.features['label'].names))\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf0855c-6501-4332-88eb-dc8e962e490a",
   "metadata": {},
   "source": [
    "1. model.train()으로 모델을 학습모드로 전환\n",
    "2. 배치 데이터를 가지고와서 모델에 입력으로 전달(input_ids,attention_mask,정답레이블 labels)\n",
    "3. 레이블과의 차이를 통해 계산된 loss값으로 역전파 수행하고, 옵티마이저의 step 호출로 역전파 결과를 바탕으로 모델 업데이트\n",
    "4. total_loss의 경우 학습이 잘되고 있는지 집게"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f70226b8-057f-4fd2-a8aa-5c92b808eba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47feebfad4f4e4aabd48db56e968ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#학습 데이터 준비\n",
    "def make_dataloader(dataset, batch_size, shuffle=True):\n",
    "    dataset = dataset.map(tokenize_function,batched=True).with_format('torch')\n",
    "    dataset = dataset.rename_column('label','labels')\n",
    "    dataset = dataset.remove_columns(column_names = ['title'])\n",
    "    return DataLoader(dataset,batch_size = batch_size, shuffle = shuffle)\n",
    "train_dataloader = make_dataloader(train_dataset,batch_size = 8, shuffle=True)\n",
    "valid_dataloader = make_dataloader(valid_dataset,batch_size = 8, shuffle=False)\n",
    "test_dataloader = make_dataloader(test_dataset,batch_size = 8, shuffle=False)\n",
    "\n",
    "#학습 함수\n",
    "def train_epoch(model, data_loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids,attention_mask=attention_mask,labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss +=loss.item()\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "516bc3bb-2ce6-4a8b-9895-e6cc2e54c3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19350ab451c84a69a33eb0c4e37825ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss : 0.6234439497977495\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30ee91aa33140e483605db807d8baba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validataion Loss : 0.573597308754921\n",
      "Validataion Accuracy : 0.817\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b452fdaf56c7414fa273a035e7eaef6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.793\n"
     ]
    }
   ],
   "source": [
    "# 평가 함수 정의\n",
    "def evaluate(model,data_loader):\n",
    "    model.eval()\n",
    "    total_loss=0\n",
    "    predictions=[]\n",
    "    true_labels=[]\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids,attention_mask=attention_mask,labels=labels)\n",
    "            logits = outputs.logits\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(logits,dim=-1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    avg_loss = total_loss/len(data_loader)\n",
    "    accuracy = np.mean(np.array(predictions) == np.array(true_labels))\n",
    "    return avg_loss,accuracy\n",
    "# 학습 루프 수행하기\n",
    "num_epochs = 1\n",
    "optimizer = AdamW(model.parameters(),lr=5e-5)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    train_loss = train_epoch(model,train_dataloader,optimizer)\n",
    "    print(f'Training loss : {train_loss}')\n",
    "    valid_loss, valid_accuracy = evaluate(model, valid_dataloader)\n",
    "    print(f\"Validataion Loss : {valid_loss}\")\n",
    "    print(f\"Validataion Accuracy : {valid_accuracy}\")\n",
    "# 테스트\n",
    "_,test_accuracy = evaluate(model,test_dataloader)\n",
    "print(f'Test Accuracy : {test_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67927b25-b8e7-4f7f-bb4a-a8bfa465c984",
   "metadata": {},
   "source": [
    "### 학습 모델 허깅페이스 업로드\n",
    "- 업로드 방법은 크게 Trainer 사용했을 때, 사용하지 않았을 때로 나뉨\n",
    "- Trainer 사용한 경우  trainer 인스턴스에서 push_to_hub() 메서드를 사용하면 학습한 모델과 토크나이저를 함께 모델 허브에 업로드한다\n",
    "- 직접 학습한 경우 모델과 토크나이저를 각각 push_to_hub()로 업로드 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c10df6c-0eca-4690-8e59-ca778a0202e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "09c4c57f-0d66-4cb0-a856-14387efe3f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to C:\\Users\\ktaek\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69efcd8b1f4940ae8125501894f1ae97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93a7978e76af46c3a0c4a38884128bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1728727849.DESKTOP-340AC9K.21016.0:   0%|          | 0.00/6.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39f30164ee34cdda8410726596f2ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b6b61dfde1841e194933d21a2ba08a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1728728705.DESKTOP-340AC9K.21016.1:   0%|          | 0.00/411 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23dde06485b04a2daefb4f49b4df41d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70f5ba2fd4f14b2a8a28ace2da019285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "679b0ec3be4f49c2babf19190892c5b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/ktaek94/roberta-base-klue-ynat-classification/commit/f91083419f86288b66322d56ca66fccce74a3243', commit_message='Upload tokenizer', commit_description='', oid='f91083419f86288b66322d56ca66fccce74a3243', pr_url=None, repo_url=RepoUrl('https://huggingface.co/ktaek94/roberta-base-klue-ynat-classification', endpoint='https://huggingface.co', repo_type='model', repo_id='ktaek94/roberta-base-klue-ynat-classification'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token = '---')\n",
    "repo_id = f\"ktaek94/roberta-base-klue-ynat-classification\"\n",
    "#Trainer사용시\n",
    "trainer.push_to_hub(repo_id)\n",
    "#직접 학습 시\n",
    "model.push_to_hub(repo_id)\n",
    "tokenizer.push_to_hub(repo_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebf4342-4e82-49c8-9a10-b55a3e054fb2",
   "metadata": {},
   "source": [
    "## 모델 추론하기\n",
    "- 모델을 활용하기 쉽도록 추상화한 파이프라인을 활용하는 방법\n",
    "- 직접 모델과 토크나이저를 불러와 활용하는 방법\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1cae3b-969c-4eb9-a5e1-bed37274b72b",
   "metadata": {},
   "source": [
    "### 파이프라인 활용한 추론\n",
    "- 토크나이저와 모델을 결합해 데이터의 전후처리와 모델 추론을 간단하게 수행하는 pipeline을 제공한다.\n",
    "- 파이프라인은 크게 작업 종류,모델, 설정을 입력으로 받는다. 작업 종류는 텍스트 분류,토큰 분류 등 작업에 맞춰 설정하고 모델에 저장소 아이디를 설정하면된다.\n",
    "- 자세한 설명은 huggingface.co/docs/transformers/main_classes/pipelines#transformers.pipeline.config에서 확인 가능하다\n",
    "- 추론하고자 하는 텍스트를 입력하면 레이블과 그 확률을 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8f269aca-0f72-4315-bafe-9ccea17a668e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['무늬만 국산 OEM 수입차 판매 반등세…차종도 다양화',\n",
       " '사우디 원유 공급 부족한가…美 증산요구에 이의',\n",
       " '게시판 KBS 안전한 대한민국 주간 특별편성',\n",
       " '이언주 참전명예수당 국민연금 평균 20%까지 인상법 발의',\n",
       " '안산소식 디딤돌 일자리 사업 참여자 37명 모집']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['title'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8f2d9c2e-15e8-4f56-aa3a-d3ae52a6b056",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9278706908226013},\n",
       " {'label': 'LABEL_4', 'score': 0.9798926115036011},\n",
       " {'label': 'LABEL_3', 'score': 0.7625777721405029},\n",
       " {'label': 'LABEL_1', 'score': 0.8380774259567261},\n",
       " {'label': 'LABEL_2', 'score': 0.781562328338623}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "model_id = 'ktaek94/roberta-base-klue-ynat-classification'\n",
    "model_pipeline = pipeline('text-classification',model=model_id)\n",
    "model_pipeline(dataset['train']['title'][:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8290fba1-c767-4bd5-8b08-744d362ba3ae",
   "metadata": {},
   "source": [
    "### 직접 추론\n",
    "- 직접 모델과 토크나이저를 불러와 추론을 구현할 수 있다.\n",
    "- __init__ 메서드에서 입력받은 모델 아이디에 맞는 모델과 토크나이저를 불러온다.\n",
    "- Custompipeline의 인스턴스를 호출 할때 __call__메서드를 사용하는데 tokenizer를 통해 토큰화를 수행\n",
    "- 모델 추론을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a71b69d7-633e-4c36-9c41-152d58049a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9278706908226013},\n",
       " {'label': 'LABEL_4', 'score': 0.9798926115036011},\n",
       " {'label': 'LABEL_3', 'score': 0.7625780701637268},\n",
       " {'label': 'LABEL_1', 'score': 0.8380774259567261},\n",
       " {'label': 'LABEL_2', 'score': 0.781562328338623}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "class CustomPipeline:\n",
    "    def __init__(self,model_id):\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_id)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "        self.model.eval()\n",
    "    def __call__(self,texts):\n",
    "        tokenized = self.tokenizer(texts, return_tensors = 'pt', padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**tokenized)\n",
    "            logits = outputs.logits\n",
    "        probabilities = softmax(logits, dim = -1)\n",
    "        scores, labels = torch.max(probabilities, dim = -1)\n",
    "        labels_str = [self.model.config.id2label[label_idx] for label_idx in labels.tolist()]\n",
    "        return [{'label' :label,'score':score.item()} for label, score in zip(labels_str,scores)]\n",
    "custom_pipeline = CustomPipeline(model_id)\n",
    "custom_pipeline(dataset['train']['title'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca5ca1a-9f46-4c7b-80f8-bfb58dc2ab50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
