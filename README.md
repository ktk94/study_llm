# [트랜스포머 이해하기](https://github.com/ktk94/study_llm/blob/main/Comprehend%20Transformers.ipynb)


# [허깅페이스 트랜스포머 사용하기](https://github.com/ktk94/study_llm/blob/main/HuggingFace%20Transformer%20Library.ipynb)


# [GPU 효율적으로 사용하기(메모리 절약, 양자화 등)](https://github.com/ktk94/study_llm/blob/main/Efficient%20learning%20with%20GPUs.ipynb
)

# [모델 경량화](https://github.com/ktk94/study_llm/blob/main/Model%20Lightweight.ipynb)


# [LLM 모델 서빙하기](https://github.com/ktk94/study_llm/blob/main/Serving%20sLLM.ipynb)
<br>
추가해야할 사항
- 로컬 서버 실행
- vLLM 오류 

# [LLM 애플리케이션 개발하기](https://github.com/ktk94/study_llm/blob/main/LLM%20Application%20Development.ipynb)

# [임베딩 모델로 데이터 의미 압축하기](https://github.com/ktk94/study_llm/blob/main/Semantics%20Compressing%20data%20with%20embedding%20models%20.ipynb)
